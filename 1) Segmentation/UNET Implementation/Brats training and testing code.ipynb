{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA is available. PyTorch version: {torch.__version__}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "    # Test a simple tensor operation on the GPU\n",
    "    x = torch.randn(3, 3).cuda()\n",
    "    y = torch.randn(3, 3).cuda()\n",
    "    z = x + y\n",
    "    \n",
    "    print(\"Tensor 'x' device: \", x.device)\n",
    "    print(\"Tensor 'y' device: \", y.device)\n",
    "    print(\"Tensor 'z' device: \", z.device)\n",
    "    print(\"Tensor operation result: \", z)\n",
    "else:\n",
    "    print(\"CUDA is not available. Please check your installation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import random\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'E:\\BRATS DATA CODES\\UNET CODES')\n",
    "from brats2020_custom_data_generator import imageLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_dir = r\"E:\\Brats Dataset\\BraTS2020_TrainingData\\input_data_128\\train\\images/\"\n",
    "train_mask_dir = r\"E:\\Brats Dataset\\BraTS2020_TrainingData\\input_data_128\\train\\masks/\"\n",
    "\n",
    "img_list = os.listdir(train_img_dir)\n",
    "msk_list = os.listdir(train_mask_dir)\n",
    "\n",
    "num_images = len(os.listdir(train_img_dir))\n",
    "\n",
    "img_num = random.randint(0,num_images-1)\n",
    "test_img = np.load(train_img_dir+img_list[img_num])\n",
    "test_mask = np.load(train_mask_dir+msk_list[img_num])\n",
    "test_mask = np.argmax(test_mask, axis=3)\n",
    "\n",
    "n_slice=random.randint(0, test_mask.shape[2])\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(test_img[:,:,n_slice, 0], cmap='gray')\n",
    "plt.title('Image flair')\n",
    "plt.subplot(222)\n",
    "plt.imshow(test_img[:,:,n_slice, 1], cmap='gray')\n",
    "plt.title('Image t1ce')\n",
    "plt.subplot(223)\n",
    "plt.imshow(test_img[:,:,n_slice, 2], cmap='gray')\n",
    "plt.title('Image t2')\n",
    "plt.subplot(224)\n",
    "plt.imshow(test_mask[:,:,n_slice])\n",
    "plt.title('Mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt0 = 0.26\n",
    "wt1 = 22.53\n",
    "wt2 = 22.53\n",
    "wt3 = 26.31\n",
    "\n",
    "#Weights are: 0.26, 22.53, 22.53, 26.21\n",
    "#wt0, wt1, wt2, wt3 = 0.26, 22.53, 22.53, 26.21\n",
    "#These weihts can be used for Dice loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_img_dir = r\"E:\\Brats Dataset\\BraTS2020_TrainingData\\input_data_128\\train\\images/\"\n",
    "train_mask_dir = r\"E:\\Brats Dataset\\BraTS2020_TrainingData\\input_data_128\\train\\masks/\"\n",
    "\n",
    "val_img_dir = r\"E:\\Brats Dataset\\BraTS2020_TrainingData\\input_data_128\\val\\images/\"\n",
    "val_mask_dir = r\"E:\\Brats Dataset\\BraTS2020_TrainingData\\input_data_128\\val\\masks/\"\n",
    "\n",
    "train_img_list=os.listdir(train_img_dir)\n",
    "train_mask_list = os.listdir(train_mask_dir)\n",
    "\n",
    "val_img_list=os.listdir(val_img_dir)\n",
    "val_mask_list = os.listdir(val_mask_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "train_img_datagen = imageLoader(train_img_dir, train_img_list, \n",
    "                                train_mask_dir, train_mask_list, batch_size)\n",
    "\n",
    "val_img_datagen = imageLoader(val_img_dir, val_img_list, \n",
    "                                val_mask_dir, val_mask_list, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, msk = train_img_datagen.__next__()\n",
    "\n",
    "img_num = random.randint(0,img.shape[0]-1)\n",
    "test_img=img[img_num]\n",
    "test_mask=msk[img_num]\n",
    "test_mask=np.argmax(test_mask, axis=3)\n",
    "\n",
    "n_slice=random.randint(0, test_mask.shape[2])\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(test_img[:,:,n_slice, 0], cmap='gray')\n",
    "plt.title('Image flair')\n",
    "plt.subplot(222)\n",
    "plt.imshow(test_img[:,:,n_slice, 1], cmap='gray')\n",
    "plt.title('Image t1ce')\n",
    "plt.subplot(223)\n",
    "plt.imshow(test_img[:,:,n_slice, 2], cmap='gray')\n",
    "plt.title('Image t2')\n",
    "plt.subplot(224)\n",
    "plt.imshow(test_mask[:,:,n_slice])\n",
    "plt.title('Mask')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "import segmentation_models_3D as sm\n",
    "\n",
    "\n",
    "# Define weights\n",
    "wt0, wt1, wt2, wt3 = 0.25, 0.25, 0.25, 0.25\n",
    "\n",
    "# Define losses\n",
    "dice_loss = sm.losses.DiceLoss(class_weights=np.array([wt0, wt1, wt2, wt3]))\n",
    "focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "total_loss = dice_loss + (1 * focal_loss)\n",
    "\n",
    "# Define metrics\n",
    "metrics = ['accuracy', sm.metrics.IOUScore(threshold=0.5)]\n",
    "\n",
    "# Learning rate\n",
    "LR = 0.0001\n",
    "\n",
    "# Define optimizer\n",
    "optim = Adam(LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import segmentation_models_3D as sm\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define weights\n",
    "wt0, wt1, wt2, wt3 = 0.25, 0.25, 0.25, 0.25\n",
    "\n",
    "# Define losses\n",
    "dice_loss = sm.losses.DiceLoss(class_weights=np.array([wt0, wt1, wt2, wt3]))\n",
    "focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "total_loss = dice_loss + (1 * focal_loss)\n",
    "\n",
    "# Define metrics\n",
    "metrics = ['accuracy', sm.metrics.IOUScore(threshold=0.5)]\n",
    "\n",
    "# Learning rate\n",
    "LR = 0.0001\n",
    "\n",
    "# Define optimizer\n",
    "optim = Adam(LR)\n",
    "\n",
    "# Define checkpoint directory\n",
    "checkpoint_dir = 'E:/saved_models/checkpoints/'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "# Define the model function\n",
    "def create_model():\n",
    "    from brats2020_3d_unet import simple_unet_model\n",
    "    return simple_unet_model(IMG_HEIGHT=128, \n",
    "                             IMG_WIDTH=128, \n",
    "                             IMG_DEPTH=128, \n",
    "                             IMG_CHANNELS=3, \n",
    "                             num_classes=4)\n",
    "\n",
    "# Instantiate model\n",
    "model = create_model()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optim, loss=total_loss, metrics=metrics)\n",
    "print(model.summary())\n",
    "\n",
    "# Define checkpoint callback\n",
    "checkpoint_path = checkpoint_dir + 'weights_epoch_{epoch:02d}.hdf5'\n",
    "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                      save_weights_only=True,\n",
    "                                      monitor='val_loss',\n",
    "                                      mode='min',\n",
    "                                      save_best_only=False,\n",
    "                                      verbose=1)\n",
    "\n",
    "# Load the latest checkpoint if available\n",
    "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "print(\"Latest checkpoint:\", latest_checkpoint)  # Debug print\n",
    "if latest_checkpoint:\n",
    "    initial_epoch = int(latest_checkpoint.split('_')[-1].split('.')[0]) + 1\n",
    "    print(f\"Loading weights from {latest_checkpoint}. Resuming from epoch {initial_epoch}.\")\n",
    "    model.load_weights(latest_checkpoint)\n",
    "else:\n",
    "    initial_epoch = 0\n",
    "    print(\"No previous checkpoints found. Starting training from epoch 0.\")\n",
    "\n",
    "# Fit the model\n",
    "steps_per_epoch = len(train_img_list) // batch_size\n",
    "val_steps_per_epoch = len(val_img_list) // batch_size\n",
    "\n",
    "print(\"Training process started...\")\n",
    "history = model.fit(train_img_datagen,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=96,\n",
    "                    initial_epoch=initial_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=val_img_datagen,\n",
    "                    validation_steps=val_steps_per_epoch,\n",
    "                    callbacks=[checkpoint_callback])\n",
    "print(\"Training process completed!\")\n",
    "\n",
    "# Define the path where you want to save the model\n",
    "model_save_path = r'E:\\saved_models\\brats_3d_2.0.hdf5'\n",
    "\n",
    "# Save the model\n",
    "model.save(model_save_path)\n",
    "print(\"Model saved successfully at:\", model_save_path)\n",
    "\n",
    "# Save the history\n",
    "history_save_path = r'E:\\saved_models\\brats_3d_2.0_history.pkl'\n",
    "with open(history_save_path, 'wb') as file:\n",
    "    pickle.dump(history.history, file)\n",
    "print(\"History saved successfully at:\", history_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import segmentation_models_3D as sm\n",
    "\n",
    "# Define weights\n",
    "wt0, wt1, wt2, wt3 = 0.25, 0.25, 0.25, 0.25\n",
    "\n",
    "# Define losses\n",
    "dice_loss = sm.losses.DiceLoss(class_weights=np.array([wt0, wt1, wt2, wt3]))\n",
    "focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "total_loss = dice_loss + (1 * focal_loss)\n",
    "\n",
    "# Define metrics\n",
    "metrics = ['accuracy', sm.metrics.IOUScore(threshold=0.5)]\n",
    "\n",
    "# Load the model with custom objects\n",
    "model_path = r'E:\\saved_models\\Brats_3d.hdf5'  # r prefix is for raw string to handle backslashes\n",
    "\n",
    "# Load the model\n",
    "my_model = load_model(model_path, \n",
    "                      custom_objects={'dice_loss_plus_1focal_loss': total_loss,\n",
    "                                      'iou_score': sm.metrics.IOUScore(threshold=0.5),\n",
    "                                      'DiceLoss': sm.losses.DiceLoss,\n",
    "                                      'CategoricalFocalLoss': sm.losses.CategoricalFocalLoss})\n",
    "\n",
    "# Now all set to continue the training process. \n",
    "history2 = my_model.fit(train_img_datagen,\n",
    "                        steps_per_epoch=steps_per_epoch,\n",
    "                        epochs=5,\n",
    "                        verbose=1,\n",
    "                        validation_data=val_img_datagen,\n",
    "                        validation_steps=val_steps_per_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = load_model(model_path, \n",
    "                      compile=False)\n",
    "\n",
    "\n",
    "#Verify IoU on a batch of images from the test dataset\n",
    "#Using built in keras function for IoU\n",
    "#Only works on TF > 2.0\n",
    "from keras.metrics import MeanIoU\n",
    "\n",
    "batch_size=1 #Check IoU for a batch of images\n",
    "test_img_datagen = imageLoader(val_img_dir, val_img_list, \n",
    "                                val_mask_dir, val_mask_list, batch_size)\n",
    "\n",
    "#Verify generator.... In python 3 next() is renamed as __next__()\n",
    "test_image_batch, test_mask_batch = test_img_datagen.__next__()\n",
    "\n",
    "test_mask_batch_argmax = np.argmax(test_mask_batch, axis=4)\n",
    "test_pred_batch = my_model.predict(test_image_batch)\n",
    "test_pred_batch_argmax = np.argmax(test_pred_batch, axis=4)\n",
    "\n",
    "n_classes = 4\n",
    "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
    "IOU_keras.update_state(test_pred_batch_argmax, test_mask_batch_argmax)\n",
    "print(\"Mean IoU =\", IOU_keras.result().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_num = 200\n",
    "\n",
    "test_img = np.load(r\"E:\\Brats Dataset\\BraTS2020_TrainingData\\input_data_128\\val\\images\\image_\" + str(img_num) + \".npy\")\n",
    "\n",
    "test_mask = np.load(r\"E:\\Brats Dataset\\BraTS2020_TrainingData\\input_data_128\\val\\masks\\mask_\" + str(img_num) + \".npy\")\n",
    "test_mask_argmax=np.argmax(test_mask, axis=3)\n",
    "\n",
    "test_img_input = np.expand_dims(test_img, axis=0)\n",
    "test_prediction = my_model.predict(test_img_input)\n",
    "test_prediction_argmax=np.argmax(test_prediction, axis=4)[0,:,:,:]\n",
    "\n",
    "\n",
    "# print(test_prediction_argmax.shape)\n",
    "print(test_mask_argmax.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "n_slice=random.randint(0, test_prediction_argmax.shape[2])\n",
    "#n_slice = 20\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(231)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(test_img[:,:,n_slice,1], cmap='gray')\n",
    "plt.subplot(232)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(test_mask_argmax[:,:,n_slice])\n",
    "plt.subplot(233)\n",
    "plt.title('Prediction on test image')\n",
    "plt.imshow(test_prediction_argmax[:,:, n_slice])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
